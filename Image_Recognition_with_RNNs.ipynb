{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image_Recognition_with_RNNs\n",
    "\n",
    "In this tutorial, we are going to learn how to use RNNs to predict numbers through images.\n",
    "\n",
    "Source:\n",
    "- hands on machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-c50d5bb4a85c>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /Users/andrewtseng/anaconda3/envs/deeplearning/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /Users/andrewtseng/anaconda3/envs/deeplearning/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/andrewtseng/anaconda3/envs/deeplearning/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/andrewtseng/anaconda3/envs/deeplearning/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to list all the `attibutes` and the `methods` in a unknown `dataset object`. So we use the `dir()` method to get access to the dataset object. we fould that there is a `train` attribute in `mnist class`. Under the `train` attribute, there are `images`, `labels`, `num_examples` attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__add__', '__class__', '__contains__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getnewargs__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__rmul__', '__setattr__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '_asdict', '_fields', '_make', '_replace', '_source', 'count', 'index', 'test', 'train', 'validation']\n",
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_epochs_completed', '_images', '_index_in_epoch', '_labels', '_num_examples', 'epochs_completed', 'images', 'labels', 'next_batch', 'num_examples']\n",
      "(55000, 784)\n",
      "(55000,)\n",
      "55000\n",
      "[7 2 1 ... 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "print(dir(mnist))\n",
    "print(dir(mnist.train))\n",
    "print(mnist.train.images.shape)\n",
    "print(mnist.train.labels.shape)\n",
    "print(mnist.train.num_examples)\n",
    "\n",
    "print(mnist.test.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 55000 images and each image is composed of `28x28 pixels`. What we are going to do is use each `row` in the image as a sequence, and the will be `28 time steps`. In other words, each time step, there are `28 inputs`. Each sequence will be fed in a cell with `150 neurons`. The only output will be at the `final cell`, where the 150 neurons* 150 neurons array would be fed in a softmax that preoduces `10 outputs` predicting the image from 0 to 9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in this case, we are only going to feed the last output (one could also say it is the last state because in vanilla RNN, the last state  equals the output), which is the second term in the (outputs, states) tuple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is a softmax function?\n",
    "The softmax function squeeses the input arguments into a valus between 0 and 1.\n",
    "$$ \\sigma(x_j) = \\frac{e^{x_j}}{\\Sigma_i e^{x_i}} $$\n",
    "\n",
    "#### What is Cross entropy loss?\n",
    "$$ H(p,q) = -\\Sigma_x p(x)logq(x) $$\n",
    "where p is the observed value and q is the estimated value.\n",
    "\n",
    "- Why use `tf.nn.sparse_softmax_cross_entropy_with_logits` to calculate the cross entropy?\n",
    "We are working on a multiclass calssification problem where the catogirical data is 0-9. If we use `softmax_cross_entropy_with_logits`, we have to transform the catogorical data to one hot vector. However, with `tf.nn.sparse_softmax_cross_entropy_with_logits`, it take cares fo the one-hot encoding precedure.\n",
    "\n",
    "Source:\n",
    "1. https://stackoverflow.com/questions/37312421/whats-the-difference-between-sparse-softmax-cross-entropy-with-logits-and-softm\n",
    "2. https://stackoverflow.com/questions/43394152/tensorflow-what-exact-formula-is-applied-in-tf-nn-sparse-softmax-cross-entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is `tf.nn.in_top_k(predictions, targets, k)`?\n",
    "\n",
    "Let the index of the 0th to kth largest value in the prediction be a set M, then if targets is in the set M, then it is true.\n",
    "\n",
    "Source:\n",
    "- https://www.cnblogs.com/logo-88/p/9099383.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8 0.4 0.5 0.6]\n",
      " [0.1 0.9 0.2 0.4]\n",
      " [0.1 0.9 0.4 0.2]]\n",
      "[1 1 1]\n",
      "[False  True  True]\n",
      "[[0.8 0.4 0.5 0.6]\n",
      " [0.1 0.9 0.2 0.4]\n",
      " [0.1 0.9 0.4 0.2]]\n",
      "[1 1 2]\n",
      "[False  True  True]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph() \n",
    "A = tf.Variable([[0.8, 0.4, 0.5, 0.6],[0.1, 0.9, 0.2, 0.4],[0.1, 0.9, 0.4, 0.2]])\n",
    "B = tf.Variable([1, 1, 1])\n",
    "result = tf.nn.in_top_k(A, B, 2)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(A))\n",
    "    print(sess.run(B))\n",
    "    print(sess.run(result))\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.reset_default_graph() \n",
    "A = tf.Variable([[0.8, 0.4, 0.5, 0.6],[0.1, 0.9, 0.2, 0.4],[0.1, 0.9, 0.4, 0.2]])\n",
    "B = tf.Variable([1, 1, 2])\n",
    "result = tf.nn.in_top_k(A, B, 2)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(A))\n",
    "    print(sess.run(B))\n",
    "    print(sess.run(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`correct = tf.nn.in_top_k(logits, y, 1)` means that is the largest value in logits is equal to y, then it is true.\n",
    "Why?\n",
    "Because if logit looks like this,\n",
    "0.1 0.2 0.0 0.8 0.4 0.6 0.0 0.1 0.1 0.3\n",
    "the index of the largest value in logits is 3, it also means that the predictor thinks that the image is 3\n",
    "Now, if the real value y is 3, then `correct = tf.nn.in_top_k(logits, 3, 1)` returns True.\n",
    "if the real value y is 5, then `correct = tf.nn.in_top_k(logits, 5, 1)` returns False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-6efd1efa2fa1>:17: BasicRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.SimpleRNNCell, and will be replaced by that in Tensorflow 2.0.\n",
      "0 Train accuracy: 0.96 Test accuracy: 0.9312\n",
      "1 Train accuracy: 0.96 Test accuracy: 0.9578\n",
      "2 Train accuracy: 0.97333336 Test accuracy: 0.9614\n",
      "3 Train accuracy: 0.9866667 Test accuracy: 0.9621\n",
      "4 Train accuracy: 0.96 Test accuracy: 0.9583\n",
      "5 Train accuracy: 0.96666664 Test accuracy: 0.9539\n",
      "6 Train accuracy: 0.97333336 Test accuracy: 0.972\n",
      "7 Train accuracy: 0.98 Test accuracy: 0.9657\n",
      "8 Train accuracy: 0.9533333 Test accuracy: 0.9635\n",
      "9 Train accuracy: 0.9866667 Test accuracy: 0.9691\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph() \n",
    "n_steps = 28\n",
    "n_inputs = 28\n",
    "n_neurons = 150\n",
    "n_outputs = 10\n",
    "learning_rate = 0.001\n",
    "n_epochs = 10\n",
    "batch_size = 150\n",
    "\n",
    "\n",
    "X_test = mnist.test.images.reshape((-1, n_steps, n_inputs))\n",
    "y_test = mnist.test.labels\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "y = tf.placeholder(tf.int32, [None])\n",
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)\n",
    "outputs, states = tf.nn.dynamic_rnn(basic_cell, X, dtype=tf.float32)\n",
    "#states is the final output\n",
    "logits = tf.layers.dense(states, n_outputs)\n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "loss = tf.reduce_mean(xentropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n",
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            X_batch = X_batch.reshape((-1, n_steps, n_inputs))\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "#             print(states.eval(feed_dict={X: X_batch, y: y_batch}).shape)\n",
    "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_test = accuracy.eval(feed_dict={X: X_test, y: y_test})\n",
    "        print(epoch, \"Train accuracy:\", acc_train, \"Test accuracy:\", acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
